dataset_config:
  vqa2:
      data_dir: ''
      depth_first: false
      fast_read: false
      use_images: false
      use_features: true
      images:
        train:
        - /home/datasets/VizWiz/train
        val:
        - /home/datasets/VizWiz/val
        test:
        - /home/datasets/VizWiz/test
      features:
        train:
        - /home/datasets/VizWiz/grid-feats-vqa/features
        val:
        - /home/datasets/VizWiz/grid-feats-vqa/featrues
        test:
        - /home/datasets/VizWiz/grid-feats-vqa/featrues
      annotations:
        train:
        - ./datasets/vizwiz/annotations/imdb_vizwiz_train.npy
        val:
        - ./datasets/vizwiz/annotations/imdb_vizwiz_val.npy
        test:
        - ./datasets/vizwiz/annotations/imdb_vizwiz_test.npy
      max_features: 100
      processors:
        text_processor:
          type: vocab
          params:
            max_length: 14
            vocab:
              type: intersected
              embedding_name: glove.6B.300d
              vocab_file: ./datasets/vizwiz/extras/vocabulary_100k.txt
            preprocessor:
              type: simple_sentence
              params: {}
        answer_processor:
          type: vqa_answer
          params:
            num_answers: 10
            vocab_file: ./datasets/vizwiz/extras/answers_vqa.txt
            preprocessor:
              type: simple_word
              params: {}
        context_processor:
          type: fasttext
          params:
            download_initially: false
            max_length: 50
            model_file: wiki.en.bin
        ocr_token_processor:
          type: simple_word
          params: {}
        bbox_processor:
          type: bbox
          params:
            max_length: 50
      return_features_info: false
      # Return OCR information
      use_ocr: false
      # Return spatial information of OCR tokens if present
      use_ocr_info: false
