{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fa538c-d314-43dc-b059-bb84922d899c",
   "metadata": {},
   "source": [
    "# 将 VizWiz 数据集转 COCO `.json` 形式\n",
    "\n",
    "- images\n",
    "- - filename\n",
    "- - id\n",
    "- - height\n",
    "- - width\n",
    "\n",
    "- annotations\n",
    "- - id\n",
    "- - category_id\n",
    "- - segmentation: []\n",
    "- - area\n",
    "- - iscrowd\n",
    "- - image_id\n",
    "- - bbox: []\n",
    "- - ignore\n",
    "- - attribute_ids: []\n",
    "\n",
    "- categories\n",
    "- - supercategory\n",
    "- - id\n",
    "- - name\n",
    "\n",
    "- attCategories\n",
    "- - supercategory\n",
    "- - id\n",
    "- - name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ff07bb-fabe-49c9-b8e9-243e51bc02ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20523it [06:31, 52.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(\"./datasets/visual_genome/annotations/visual_genome_train.json\", \"r\") as f:\n",
    "    vg_train_data = json.load(f)\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "train_data\n",
    "res = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': vg_train_data['categories'],\n",
    "    'attCategories': vg_train_data['attCategories']\n",
    "}\n",
    "\n",
    "\n",
    "for i, ann in tqdm(enumerate(train_data)):\n",
    "    img = cv2.imread(os.path.join(\"./datasets/vizwiz/images/\", ann['image']))\n",
    "    H, W, C = img.shape\n",
    "    image_item = {\n",
    "        'file_name': ann['image'],\n",
    "        'id': i,\n",
    "        'height': H,\n",
    "        'width': W,\n",
    "    }\n",
    "    annotations_item = {\n",
    "        'id': i,\n",
    "        'category_id': 0,\n",
    "        'segmentation': [],\n",
    "        'area': 0,\n",
    "        'iscrowd': False,\n",
    "        'image_id': i,\n",
    "        'bbox': [],\n",
    "        'ignore': 0,\n",
    "        'attribute_ids': []\n",
    "    }\n",
    "    res['images'].append(image_item)\n",
    "    res['annotations'].append(annotations_item)\n",
    "    # break\n",
    "    \n",
    "with open(\"./datasets/vizwiz/annotations/vizwiz_train.json\", \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccc5754-f8a7-4000-8c1e-86f3603780d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4319it [01:22, 52.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(\"./datasets/visual_genome/annotations/visual_genome_val.json\", \"r\") as f:\n",
    "    vg_val_data = json.load(f)\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "res = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': vg_val_data['categories'],\n",
    "    'attCategories': vg_val_data['attCategories']\n",
    "}\n",
    "\n",
    "\n",
    "for i, ann in tqdm(enumerate(val_data)):\n",
    "    img = cv2.imread(os.path.join(\"./datasets/vizwiz/images/\", ann['image']))\n",
    "    H, W, C = img.shape\n",
    "    image_item = {\n",
    "        'file_name': ann['image'],\n",
    "        'id': i,\n",
    "        'height': H,\n",
    "        'width': W,\n",
    "    }\n",
    "    annotations_item = {\n",
    "        'id': i,\n",
    "        'category_id': 0,\n",
    "        'segmentation': [],\n",
    "        'area': 0,\n",
    "        'iscrowd': False,\n",
    "        'image_id': i,\n",
    "        'bbox': [],\n",
    "        'ignore': 0,\n",
    "        'attribute_ids': []\n",
    "    }\n",
    "    res['images'].append(image_item)\n",
    "    res['annotations'].append(annotations_item)\n",
    "    # break\n",
    "    \n",
    "with open(\"./datasets/vizwiz/annotations/vizwiz_val.json\", \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec074c9-1f5a-4eb5-bd07-1a9988f07621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [02:24, 55.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(\"./datasets/visual_genome/annotations/visual_genome_test.json\", \"r\") as f:\n",
    "    vg_test_data = json.load(f)\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "res = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': vg_test_data['categories'],\n",
    "    'attCategories': vg_test_data['attCategories']\n",
    "}\n",
    "\n",
    "\n",
    "for i, ann in tqdm(enumerate(test_data)):\n",
    "    img = cv2.imread(os.path.join(\"./datasets/vizwiz/images/\", ann['image']))\n",
    "    H, W, C = img.shape\n",
    "    image_item = {\n",
    "        'file_name': ann['image'],\n",
    "        'id': i,\n",
    "        'height': H,\n",
    "        'width': W,\n",
    "    }\n",
    "    annotations_item = {\n",
    "        'id': i,\n",
    "        'category_id': 0,\n",
    "        'segmentation': [],\n",
    "        'area': 0,\n",
    "        'iscrowd': False,\n",
    "        'image_id': i,\n",
    "        'bbox': [],\n",
    "        'ignore': 0,\n",
    "        'attribute_ids': []\n",
    "    }\n",
    "    res['images'].append(image_item)\n",
    "    res['annotations'].append(annotations_item)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/annotations/vizwiz_test.json\", \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15863a0e-b2a5-4402-bb37-d05807387120",
   "metadata": {},
   "source": [
    "# 将 VizWiz 数据集转 COCO `.json` 形式 (train + val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1adaba-5a04-4a3d-8bdc-9c906dd67f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24842it [08:20, 49.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"./datasets/visual_genome/annotations/visual_genome_val.json\", \"r\") as f:\n",
    "    vg_val_data = json.load(f)\n",
    "    \n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "train_val = train_data + val_data\n",
    "\n",
    "res = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': vg_val_data['categories'],\n",
    "    'attCategories': vg_val_data['attCategories']\n",
    "}\n",
    "\n",
    "\n",
    "for i, ann in tqdm(enumerate(train_val)):\n",
    "    img = cv2.imread(os.path.join(\"/home/datasets/VizWiz/train_val/\", ann['image']))\n",
    "    # print(os.path.join(\"/home/datasets/VizWiz/train_val/\", ann['image']))\n",
    "    H, W, C = img.shape\n",
    "    image_item = {\n",
    "        'file_name': ann['image'],\n",
    "        'id': i,\n",
    "        'height': H,\n",
    "        'width': W,\n",
    "    }\n",
    "    annotations_item = {\n",
    "        'id': i,\n",
    "        'category_id': 0,\n",
    "        'segmentation': [],\n",
    "        'area': 0,\n",
    "        'iscrowd': False,\n",
    "        'image_id': i,\n",
    "        'bbox': [],\n",
    "        'ignore': 0,\n",
    "        'attribute_ids': []\n",
    "    }\n",
    "    res['images'].append(image_item)\n",
    "    res['annotations'].append(annotations_item)\n",
    "    # break\n",
    "    \n",
    "with open(\"./datasets/vizwiz/annotations_kfold/vizwiz_train_val.json\", \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28891b-ba67-45a1-b275-af9f060cb9f0",
   "metadata": {},
   "source": [
    "# 查看 mmf vqa2 grid features 的数据格式\n",
    "\n",
    "index 0: \n",
    "- create_time \n",
    "- dataset_name\n",
    "- version\n",
    "- has_answer\n",
    "- has_gt_layout\n",
    "- created_at\n",
    "\n",
    "other index:\n",
    "- image_name\n",
    "- image_id\n",
    "- question_id\n",
    "- feature_path\n",
    "- question_str\n",
    "- question_tokens: []\n",
    "- all_answers: []\n",
    "- ocr_tokens: []\n",
    "- answer: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa375aa-5e19-4e78-93a4-ca01e7393d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "{'create_time': '2018-04-18 13:01', 'dataset_name': 'vqa', 'version': 1, 'has_answer': True, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      "{'image_name': 'COCO_val2014_000000262162', 'image_id': 262162, 'question_id': 262162000, 'feature_path': 'val2014/262162.pth', 'question_str': 'Is that a folding chair?', 'question_tokens': ['is', 'that', 'a', 'folding', 'chair'], 'all_answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'], 'ocr_tokens': [], 'answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vqa2_minival = np.load(\"./datasets/vqa2/annotations_grid/imdb_oneval2014.npy\", allow_pickle=True)\n",
    "print(len(vqa2_minival))\n",
    "print(vqa2_minival[0])\n",
    "print(vqa2_minival[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8419fe9f-aafb-4e22-bf52-be8162480a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214355\n",
      "{'create_time': '2018-03-29 16:39', 'dataset_name': 'vqa', 'version': 1, 'has_answer': True, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      "[{'create_time': '2018-03-29 16:39', 'dataset_name': 'vqa', 'version': 1, 'has_answer': True, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      " {'image_name': 'val2014/COCO_val2014_000000262148', 'image_id': 262148, 'question_id': 262148000, 'feature_path': 'val2014/262148.pth', 'question_str': 'Where is he looking?', 'question_tokens': ['where', 'is', 'he', 'looking'], 'all_answers': ['down', 'down', 'at table', 'skateboard', 'down', 'table', 'down', 'down', 'down', 'down'], 'ocr_tokens': ['etil', 'Johans'], 'answers': ['down', 'down', 'at table', 'skateboard', 'down', 'table', 'down', 'down', 'down', 'down']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000262148', 'image_id': 262148, 'question_id': 262148001, 'feature_path': 'val2014/262148.pth', 'question_str': 'What are the people in the background doing?', 'question_tokens': ['what', 'are', 'the', 'people', 'in', 'the', 'background', 'doing'], 'all_answers': ['spectating', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching'], 'ocr_tokens': ['etil', 'Johans'], 'answers': ['watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching', 'watching']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000262148', 'image_id': 262148, 'question_id': 262148002, 'feature_path': 'val2014/262148.pth', 'question_str': 'What is he on top of?', 'question_tokens': ['what', 'is', 'he', 'on', 'top', 'of'], 'all_answers': ['table', 'table', 'table', 'picnic table', 'picnic table', 'picnic table', 'picnic table', 'picnic table', 'skateboard', 'picnic table'], 'ocr_tokens': ['etil', 'Johans'], 'answers': ['table', 'table', 'table', 'picnic table', 'picnic table', 'picnic table', 'picnic table', 'picnic table', 'skateboard', 'picnic table']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393225', 'image_id': 393225, 'question_id': 393225000, 'feature_path': 'val2014/393225.pth', 'question_str': 'What website copyrighted the picture?', 'question_tokens': ['what', 'website', 'copyrighted', 'the', 'picture'], 'all_answers': ['foodiebakercom', 'foodiebakercom', 'foodiebaker', 'foodiebakercom', 'foodiebakercom', 'http://foodiebakercom', 'foodiebakercom', 'foodiebakercom', 'foodiebakercom', 'foodiebaker'], 'ocr_tokens': ['OHTTP:/FOODIEBAKER.GOM'], 'answers': ['<unk>']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393225', 'image_id': 393225, 'question_id': 393225001, 'feature_path': 'val2014/393225.pth', 'question_str': 'Is this a creamy soup?', 'question_tokens': ['is', 'this', 'a', 'creamy', 'soup'], 'all_answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'], 'ocr_tokens': ['OHTTP:/FOODIEBAKER.GOM'], 'answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393225', 'image_id': 393225, 'question_id': 393225002, 'feature_path': 'val2014/393225.pth', 'question_str': 'Is this rice noodle soup?', 'question_tokens': ['is', 'this', 'rice', 'noodle', 'soup'], 'all_answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'], 'ocr_tokens': ['OHTTP:/FOODIEBAKER.GOM'], 'answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393225', 'image_id': 393225, 'question_id': 393225003, 'feature_path': 'val2014/393225.pth', 'question_str': 'What is to the right of the soup?', 'question_tokens': ['what', 'is', 'to', 'the', 'right', 'of', 'the', 'soup'], 'all_answers': ['chopsticks', 'chopsticks', 'chopsticks', 'chopsticks', 'chopsticks', 'shrimp', 'chopsticks', 'chopsticks', 'chopsticks', 'chopsticks spoon'], 'ocr_tokens': ['OHTTP:/FOODIEBAKER.GOM'], 'answers': ['chopsticks', 'chopsticks', 'chopsticks', 'chopsticks', 'chopsticks', 'shrimp', 'chopsticks', 'chopsticks', 'chopsticks']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393226', 'image_id': 393226, 'question_id': 393226000, 'feature_path': 'val2014/393226.pth', 'question_str': 'What is the man doing in the street?', 'question_tokens': ['what', 'is', 'the', 'man', 'doing', 'in', 'the', 'street'], 'all_answers': ['crossing it', 'walking', 'walking', 'crossing', 'crossing road', 'walking', 'crossing', 'walking', 'crossing', 'walking'], 'ocr_tokens': ['SLOW!', 'MpinSain', 'SUNDAES', 'SHAKES', 'CONES'], 'answers': ['walking', 'walking', 'crossing', 'walking', 'crossing', 'walking', 'crossing', 'walking']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393226', 'image_id': 393226, 'question_id': 393226001, 'feature_path': 'val2014/393226.pth', 'question_str': \"How many photo's can you see?\", 'question_tokens': ['how', 'many', 'photo', \"'\", 's', 'can', 'you', 'see'], 'all_answers': ['1', '1', '4', '4', '4', '1', '1', '4', '1', '1'], 'ocr_tokens': ['SLOW!', 'MpinSain', 'SUNDAES', 'SHAKES', 'CONES'], 'answers': ['1', '1', '4', '4', '4', '1', '1', '4', '1', '1']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000393226', 'image_id': 393226, 'question_id': 393226002, 'feature_path': 'val2014/393226.pth', 'question_str': 'What does the truck on the left sell?', 'question_tokens': ['what', 'does', 'the', 'truck', 'on', 'the', 'left', 'sell'], 'all_answers': ['ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream'], 'ocr_tokens': ['SLOW!', 'MpinSain', 'SUNDAES', 'SHAKES', 'CONES'], 'answers': ['ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream', 'ice cream']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000240301', 'image_id': 240301, 'question_id': 240301000, 'feature_path': 'val2014/240301.pth', 'question_str': 'Why is there a gap between the roof and wall?', 'question_tokens': ['why', 'is', 'there', 'a', 'gap', 'between', 'the', 'roof', 'and', 'wall'], 'all_answers': ['ventilation', 'provide air', 'to air out barn from stinky bovines', 'keep cow safe', 'airflow', 'to let sunlight in', 'yes', 'yes', 'for air', 'air'], 'ocr_tokens': [], 'answers': ['yes', 'yes', 'air']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000240301', 'image_id': 240301, 'question_id': 240301001, 'feature_path': 'val2014/240301.pth', 'question_str': 'Is it daylight in this picture?', 'question_tokens': ['is', 'it', 'daylight', 'in', 'this', 'picture'], 'all_answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'], 'ocr_tokens': [], 'answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000240301', 'image_id': 240301, 'question_id': 240301002, 'feature_path': 'val2014/240301.pth', 'question_str': 'Why is the cow laying down?', 'question_tokens': ['why', 'is', 'the', 'cow', 'laying', 'down'], 'all_answers': ['tired', 'tired', '4', 'resting', 'tired', 'tired', 'resting', 'tired', \"it's tired\", 'tired'], 'ocr_tokens': [], 'answers': ['tired', 'tired', '4', 'resting', 'tired', 'tired', 'resting', 'tired', 'tired']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000131089', 'image_id': 131089, 'question_id': 131089000, 'feature_path': 'val2014/131089.pth', 'question_str': 'What color is the grass in this picture?', 'question_tokens': ['what', 'color', 'is', 'the', 'grass', 'in', 'this', 'picture'], 'all_answers': ['gray', 'green', 'green', 'black, white', 'green', 'gray', 'green', 'brown', 'gray', 'green'], 'ocr_tokens': [], 'answers': ['gray', 'green', 'green', 'green', 'gray', 'green', 'brown', 'gray', 'green']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000131089', 'image_id': 131089, 'question_id': 131089001, 'feature_path': 'val2014/131089.pth', 'question_str': 'Did the batter hit the ball?', 'question_tokens': ['did', 'the', 'batter', 'hit', 'the', 'ball'], 'all_answers': ['no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes'], 'ocr_tokens': [], 'answers': ['no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000131089', 'image_id': 131089, 'question_id': 131089002, 'feature_path': 'val2014/131089.pth', 'question_str': 'How many are playing ball?', 'question_tokens': ['how', 'many', 'are', 'playing', 'ball'], 'all_answers': ['1', '1', '1', '1', '1', '1', '1', '1', '1', 'boy'], 'ocr_tokens': [], 'answers': ['1', '1', '1', '1', '1', '1', '1', '1', '1', 'boy']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000131089', 'image_id': 131089, 'question_id': 131089003, 'feature_path': 'val2014/131089.pth', 'question_str': 'Is there a chain link fence in the image?', 'question_tokens': ['is', 'there', 'a', 'chain', 'link', 'fence', 'in', 'the', 'image'], 'all_answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'], 'ocr_tokens': [], 'answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000131089', 'image_id': 131089, 'question_id': 131089004, 'feature_path': 'val2014/131089.pth', 'question_str': 'Is the boy playing baseball?', 'question_tokens': ['is', 'the', 'boy', 'playing', 'baseball'], 'all_answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'], 'ocr_tokens': [], 'answers': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']}\n",
      " {'image_name': 'val2014/COCO_val2014_000000262162', 'image_id': 262162, 'question_id': 262162000, 'feature_path': 'val2014/262162.pth', 'question_str': 'Is that a folding chair?', 'question_tokens': ['is', 'that', 'a', 'folding', 'chair'], 'all_answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no'], 'ocr_tokens': [], 'answers': ['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vqa2_val = np.load(\"./datasets/vqa2/annotations_grid/imdb_val2014.npy\", allow_pickle=True)\n",
    "print(len(vqa2_val))\n",
    "print(vqa2_val[0])\n",
    "print(vqa2_val[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4023e3-1072-4645-9ac6-4a2a426e528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447794\n",
      "{'create_time': '2018-03-29 16:39', 'dataset_name': 'vqa', 'version': 1, 'has_answer': False, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      "{'image_name': 'test2015/COCO_test2015_000000262144', 'image_id': 262144, 'question_id': 262144000, 'feature_path': 'test2015/262144.pth', 'question_str': 'Is the ball flying towards the batter?', 'question_tokens': ['is', 'the', 'ball', 'flying', 'towards', 'the', 'batter'], 'ocr_tokens': ['420', 'masslottery.com', 'jett']}\n",
      "[{'create_time': '2018-03-29 16:39', 'dataset_name': 'vqa', 'version': 1, 'has_answer': False, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      " {'image_name': 'test2015/COCO_test2015_000000262144', 'image_id': 262144, 'question_id': 262144004, 'feature_path': 'test2015/262144.pth', 'question_str': 'Will he catch the ball in time?', 'question_tokens': ['will', 'he', 'catch', 'the', 'ball', 'in', 'time'], 'ocr_tokens': ['420', 'masslottery.com', 'jett']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000524292', 'image_id': 524292, 'question_id': 524292000, 'feature_path': 'test2015/524292.pth', 'question_str': 'What function is served by the item the giraffe is peering into?', 'question_tokens': ['what', 'function', 'is', 'served', 'by', 'the', 'item', 'the', 'giraffe', 'is', 'peering', 'into'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131079', 'image_id': 131079, 'question_id': 131079000, 'feature_path': 'test2015/131079.pth', 'question_str': 'Is it raining?', 'question_tokens': ['is', 'it', 'raining'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131083', 'image_id': 131083, 'question_id': 131083002, 'feature_path': 'test2015/131083.pth', 'question_str': 'What type of garment or accessory is being worn by both people?', 'question_tokens': ['what', 'type', 'of', 'garment', 'or', 'accessory', 'is', 'being', 'worn', 'by', 'both', 'people'], 'ocr_tokens': ['Tus', 'maging']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131083', 'image_id': 131083, 'question_id': 131083007, 'feature_path': 'test2015/131083.pth', 'question_str': 'Is there an plate?', 'question_tokens': ['is', 'there', 'an', 'plate'], 'ocr_tokens': ['Tus', 'maging']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131083', 'image_id': 131083, 'question_id': 131083012, 'feature_path': 'test2015/131083.pth', 'question_str': \"Is the girl's mouth closed?\", 'question_tokens': ['is', 'the', 'girl', \"'\", 's', 'mouth', 'closed'], 'ocr_tokens': ['Tus', 'maging']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000524301', 'image_id': 524301, 'question_id': 524301002, 'feature_path': 'test2015/524301.pth', 'question_str': 'Did the cat eat the food on the plate?', 'question_tokens': ['did', 'the', 'cat', 'eat', 'the', 'food', 'on', 'the', 'plate'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000377092', 'image_id': 377092, 'question_id': 377092001, 'feature_path': 'test2015/377092.pth', 'question_str': 'What are the lines in the sky?', 'question_tokens': ['what', 'are', 'the', 'lines', 'in', 'the', 'sky'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000000016', 'image_id': 16, 'question_id': 16003, 'feature_path': 'test2015/16.pth', 'question_str': \"What color is the man's helmet:?\", 'question_tokens': ['what', 'color', 'is', 'the', 'man', \"'\", 's', 'helmet', ':'], 'ocr_tokens': ['22']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131090', 'image_id': 131090, 'question_id': 131090000, 'feature_path': 'test2015/131090.pth', 'question_str': 'Is the trash empty or full?', 'question_tokens': ['is', 'the', 'trash', 'empty', 'or', 'full'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131090', 'image_id': 131090, 'question_id': 131090005, 'feature_path': 'test2015/131090.pth', 'question_str': 'Is there hand soap on the sink?', 'question_tokens': ['is', 'there', 'hand', 'soap', 'on', 'the', 'sink'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131091', 'image_id': 131091, 'question_id': 131091000, 'feature_path': 'test2015/131091.pth', 'question_str': 'Would you be afraid of getting mugged here?', 'question_tokens': ['would', 'you', 'be', 'afraid', 'of', 'getting', 'mugged', 'here'], 'ocr_tokens': ['Fola', 'POTE-GRADHY']}\n",
      " {'image_name': 'test2015/COCO_test2015_000000262164', 'image_id': 262164, 'question_id': 262164002, 'feature_path': 'test2015/262164.pth', 'question_str': 'What animal is this?', 'question_tokens': ['what', 'animal', 'is', 'this'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000393238', 'image_id': 393238, 'question_id': 393238002, 'feature_path': 'test2015/393238.pth', 'question_str': 'What do you call this sports location?', 'question_tokens': ['what', 'do', 'you', 'call', 'this', 'sports', 'location'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000393238', 'image_id': 393238, 'question_id': 393238007, 'feature_path': 'test2015/393238.pth', 'question_str': 'What is the person holding?', 'question_tokens': ['what', 'is', 'the', 'person', 'holding'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000393239', 'image_id': 393239, 'question_id': 393239002, 'feature_path': 'test2015/393239.pth', 'question_str': 'Is this the watering hole?', 'question_tokens': ['is', 'this', 'the', 'watering', 'hole'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000131096', 'image_id': 131096, 'question_id': 131096004, 'feature_path': 'test2015/131096.pth', 'question_str': 'What is the chair made of?', 'question_tokens': ['what', 'is', 'the', 'chair', 'made', 'of'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000262169', 'image_id': 262169, 'question_id': 262169003, 'feature_path': 'test2015/262169.pth', 'question_str': 'What kind of animal is this?', 'question_tokens': ['what', 'kind', 'of', 'animal', 'is', 'this'], 'ocr_tokens': []}\n",
      " {'image_name': 'test2015/COCO_test2015_000000000027', 'image_id': 27, 'question_id': 27000, 'feature_path': 'test2015/27.pth', 'question_str': 'Where is the white fencing?', 'question_tokens': ['where', 'is', 'the', 'white', 'fencing'], 'ocr_tokens': []}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vqa2_test = np.load(\"./datasets/vqa2/annotations_grid/imdb_test2015.npy\", allow_pickle=True)\n",
    "print(len(vqa2_test))\n",
    "print(vqa2_test[0])\n",
    "print(vqa2_test[1])\n",
    "print(vqa2_test[:100:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732efa8f-f76e-4e39-b4f2-5431aae301ad",
   "metadata": {},
   "source": [
    "# 查看 mmf vqa2 region features 的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66b7b64-5260-4100-9ad9-682968eb49dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001\n",
      "{'create_time': '2018-03-29 16:39', 'dataset_name': 'vqa', 'version': 1, 'has_answer': True, 'has_gt_layout': False, 'created_at': <built-in function time>}\n",
      "{'image_name': 'COCO_val2014_000000573843', 'image_id': 573843, 'question_id': 573843005, 'feature_path': 'COCO_val2014_000000573843.npy', 'question_str': 'Are there clouds?', 'question_tokens': ['are', 'there', 'clouds'], 'all_answers': ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'], 'ocr_tokens': [], 'answers': ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vqa2_minival = np.load(\"./datasets/vqa2/annotations/imdb_minival2014.npy\", allow_pickle=True)\n",
    "print(len(vqa2_minival))\n",
    "print(vqa2_minival[0])\n",
    "print(vqa2_minival[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f379e49-52f8-421a-aa18-fde5c70d9414",
   "metadata": {},
   "source": [
    "# 将 vizwiz 数据集转为 mmf grid features 所需格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967e7b55-59b4-4adc-aa86-8b1dd4a547cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3860it [00:00, 29469.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20523\n",
      "{'image': 'VizWiz_train_00000000.jpg', 'question': \"What's the name of this product?\", 'answers': [{'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}], 'answer_type': 'other', 'answerable': 1}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20523it [00:00, 75390.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(train_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    item = {\n",
    "        'image_name' : ann['image'].split('.')[0],\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'train/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': [],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_train.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755b412e-e675-40da-9b4f-9fe1c03b9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4319it [00:00, 113601.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4319\n",
      "{'image': 'VizWiz_val_00000000.jpg', 'question': 'Ok. There is another picture I hope it is a better one.', 'answers': [{'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'maybe'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'no'}, {'answer': 'cannot repair this computer automatically', 'answer_confidence': 'maybe'}, {'answer': 'blank screen', 'answer_confidence': 'yes'}], 'answer_type': 'unanswerable', 'answerable': 0}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "print(len(val_data))\n",
    "print(val_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(val_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    item = {\n",
    "        'image_name' : ann['image'].split('.')[0],\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'val/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': [],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_val.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0495a988-5477-4dda-bd80-f6bccf2876d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:00, 51827.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "{'image': 'VizWiz_test_00000000.jpg', 'question': 'What is this? And what color is it?'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(test_data)):\n",
    "    item = {\n",
    "        'image_name' : ann['image'].split('.')[0],\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'test/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'ocr_tokens': [],\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_test.npy\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87835970-7ebd-4fec-91ee-da9b3033a5f2",
   "metadata": {},
   "source": [
    "# 将 VizWiz 训练集和验证集合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2a483f-babe-4826-bbb3-f2b74f5f5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20523\n",
      "4319\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "\n",
    "train_val = train_data + val_data\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train_val.json\", \"w\") as f:\n",
    "    json.dump(train_val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0eb4c9-4f5a-4a89-95e2-be84f917fbb0",
   "metadata": {},
   "source": [
    "# 将 vizwiz 数据集转为 mmf region features 所需格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c528d7-8459-441d-b328-dc8ba0ff8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14998it [00:00, 40217.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20523\n",
      "{'image': 'VizWiz_train_00000000.jpg', 'question': \"What's the name of this product?\", 'answers': [{'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}], 'answer_type': 'other', 'answerable': 1}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20523it [00:00, 83117.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(train_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'train/' + f'{image_name}.npy',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': [],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_train.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04eaa8d2-5a59-406d-b5b7-086ab4c572c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4319it [00:00, 76838.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4319\n",
      "{'image': 'VizWiz_val_00000000.jpg', 'question': 'Ok. There is another picture I hope it is a better one.', 'answers': [{'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'maybe'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'no'}, {'answer': 'cannot repair this computer automatically', 'answer_confidence': 'maybe'}, {'answer': 'blank screen', 'answer_confidence': 'yes'}], 'answer_type': 'unanswerable', 'answerable': 0}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "print(len(val_data))\n",
    "print(val_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(val_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'val/' + f'{image_name}.npy',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': [],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_val.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2188896-2c4d-45f0-93c2-e61fdb5e488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:00, 143732.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "{'image': 'VizWiz_test_00000000.jpg', 'question': 'What is this? And what color is it?'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(test_data)):\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'test/' + f'{image_name}.npy',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'ocr_tokens': [],\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_test.npy\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df5aa5-d87d-4951-80d3-82986d0628f3",
   "metadata": {},
   "source": [
    "# Vizwiz Train + Val CLIP Features 数据集制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7452f4ec-0be8-4d2c-98f9-4586ab1840e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11489it [00:00, 114885.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24842\n",
      "{'image': 'VizWiz_train_00000000.jpg', 'question': \"What's the name of this product?\", 'answers': [{'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}], 'answer_type': 'other', 'answerable': 1}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24842it [00:00, 115744.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train_val.json\", \"r\") as f:\n",
    "    train_val_data = json.load(f)\n",
    "    \n",
    "print(len(train_val_data))\n",
    "print(train_val_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(train_val_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'train_val/' + f'{image_name}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': [],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations/imdb_vizwiz_train_val.npy\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c00dc-5a1a-4557-9752-9f684c73cd8e",
   "metadata": {},
   "source": [
    "# 转换 anwser.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c2d42d-8232-4658-9f31-0339ba6e5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/VizWizVQA/lxmert/data/vizwiz/trainval_label2ans.json\", \"r\") as f:\n",
    "    label2ans = json.load(f)\n",
    "    \n",
    "print(label2ans)\n",
    "\n",
    "with open(\"./datasets/vizwiz/extra/answers.txt\", \"w\") as f:\n",
    "    for ans in label2ans:\n",
    "        f.write(ans + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbed241f-b030-46a5-a534-ab6eb189d2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 31, 2560])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "feat = torch.load(\"/home/datasets/VizWiz/grid-feats-vqa/clip/RN50x4/val/0.pth\")\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae2e25-f369-4173-b5a7-cfa2911089f4",
   "metadata": {},
   "source": [
    "# 将 VizWiz 数据集 转化 为 mmf 所需格式 + PaddleOCR tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08385e0-6e2f-407d-b969-9daa65f6238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6310it [00:00, 63097.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20523\n",
      "{'image': 'VizWiz_train_00000000.jpg', 'question': \"What's the name of this product?\", 'answers': [{'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}], 'answer_type': 'other', 'answerable': 1}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20523it [00:00, 54582.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/train_ocr_result.json\", \"r\") as f:\n",
    "    train_paddle_ocr = json.load(f)\n",
    "\n",
    "    \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(train_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    ocrs = train_paddle_ocr[ann['image']]\n",
    "    ocr_tokens = []\n",
    "    for ocr in ocrs:\n",
    "        if ocr['confidence'] > 0.9:\n",
    "            ocr_tokens += tokenize(ocr['text'])\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'train/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': ocr_tokens,\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations_paddleocr/imdb_vizwiz_train.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21071c91-8040-42bd-b691-686124a23171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4319it [00:00, 59431.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4319\n",
      "{'image': 'VizWiz_val_00000000.jpg', 'question': 'Ok. There is another picture I hope it is a better one.', 'answers': [{'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'maybe'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'yes'}, {'answer': 'unanswerable', 'answer_confidence': 'no'}, {'answer': 'cannot repair this computer automatically', 'answer_confidence': 'maybe'}, {'answer': 'blank screen', 'answer_confidence': 'yes'}], 'answer_type': 'unanswerable', 'answerable': 0}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/val_ocr_result.json\", \"r\") as f:\n",
    "    val_paddle_ocr = json.load(f)\n",
    "    \n",
    "print(len(val_data))\n",
    "print(val_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(val_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    ocrs = val_paddle_ocr[ann['image']]\n",
    "    ocr_tokens = []\n",
    "    for ocr in ocrs:\n",
    "        if ocr['confidence'] > 0.9:\n",
    "            ocr_tokens += tokenize(ocr['text'])\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'val/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': ocr_tokens,\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations_paddleocr/imdb_vizwiz_val.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c1c115-77e6-4ba2-819c-9347064d4b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "972it [00:00, 4848.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8000\n",
      "{'image': 'VizWiz_test_00000000.jpg', 'question': 'What is this? And what color is it?'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:00, 27063.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/test_ocr_result.json\", \"r\") as f:\n",
    "    test_paddle_ocr = json.load(f)\n",
    "    \n",
    "print(\"VizWiz_test_00000000.jpg\" in test_paddle_ocr.keys())\n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(test_data)):\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    ocrs = test_paddle_ocr[ann['image']]\n",
    "    ocr_tokens = []\n",
    "    for ocr in ocrs:\n",
    "        if ocr['confidence'] > 0.9:\n",
    "            ocr_tokens += tokenize(ocr['text'])\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'test/' + f'{i}.pth',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'ocr_tokens': ocr_tokens,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/annotations_paddleocr/imdb_vizwiz_test.npy\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd384d4-4ccb-4591-b1e7-7fba368169df",
   "metadata": {},
   "source": [
    "# Vizwiz Train + Val CLIP Features + PaddleOCR 数据集制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d51a7f46-2d59-4090-b25b-3b8665d6c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5458it [00:00, 54579.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24842\n",
      "{'image': 'VizWiz_train_00000000.jpg', 'question': \"What's the name of this product?\", 'answers': [{'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil leaves'}, {'answer_confidence': 'yes', 'answer': 'basil'}], 'answer_type': 'other', 'answerable': 1}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24842it [00:00, 54886.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/train_val.json\", \"r\") as f:\n",
    "    train_val_data = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/train_ocr_result.json\", \"r\") as f:\n",
    "    train_paddle_ocr = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/val_ocr_result.json\", \"r\") as f:\n",
    "    val_paddle_ocr = json.load(f)\n",
    "\n",
    "\n",
    "train_val_paddle_ocr = {}\n",
    "train_val_paddle_ocr.update(train_paddle_ocr)\n",
    "train_val_paddle_ocr.update(val_paddle_ocr)\n",
    "print(len(train_val_data))\n",
    "print(train_val_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(train_val_data)):\n",
    "    answers = [ans['answer'] for ans in ann['answers']]\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    ocrs = train_val_paddle_ocr[ann['image']]\n",
    "    ocr_tokens = []\n",
    "    for ocr in ocrs:\n",
    "        if ocr['confidence'] > 0.9:\n",
    "            ocr_tokens += tokenize(ocr['text'])\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'train_val/' + f'{image_name}.npy',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'all_answers': answers,\n",
    "        'ocr_tokens': ocr_tokens[:7],\n",
    "        'answers': answers,\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "np.save(\"./datasets/vizwiz/pythia_annotations_paddleocr/imdb_vizwiz_train_val.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0225662c-0f11-487c-9e94-d0113cda5593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:00, 59870.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8000\n",
      "{'image': 'VizWiz_test_00000000.jpg', 'question': 'What is this? And what color is it?'}\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "SENTENCE_SPLIT_REGEX = re.compile(r\"(\\W+)\")\n",
    "\n",
    "def tokenize(sentence, regex=SENTENCE_SPLIT_REGEX, keep=None, remove=None):\n",
    "    if keep is None:\n",
    "        keep = [\"'s\"]\n",
    "    if remove is None:\n",
    "        remove = [\",\", \"?\"]\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    for token in keep:\n",
    "        sentence = sentence.replace(token, \" \" + token)\n",
    "\n",
    "    for token in remove:\n",
    "        sentence = sentence.replace(token, \"\")\n",
    "\n",
    "    tokens = regex.split(sentence)\n",
    "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "with open(\"/home/datasets/VizWiz/Annotations/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "with open(\"./datasets/vizwiz/test_ocr_result.json\", \"r\") as f:\n",
    "    test_paddle_ocr = json.load(f)\n",
    "    \n",
    "print(\"VizWiz_test_00000000.jpg\" in test_paddle_ocr.keys())\n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "res = []\n",
    "index_0 = {\n",
    "    'create_time': '2018-04-18 13:01', \n",
    "    'dataset_name': 'vizwiz', \n",
    "    'version': 1, \n",
    "    'has_answer': True, \n",
    "    'has_gt_layout': False, \n",
    "    'created_at': ''\n",
    "}\n",
    "res.append(index_0)\n",
    "for i, ann in tqdm(enumerate(test_data)):\n",
    "    image_name = ann['image'].split('.')[0]\n",
    "    ocrs = test_paddle_ocr[ann['image']]\n",
    "    ocr_tokens = []\n",
    "    for ocr in ocrs:\n",
    "        if ocr['confidence'] > 0.9:\n",
    "            ocr_tokens += tokenize(ocr['text'])\n",
    "    item = {\n",
    "        'image_name' : image_name,\n",
    "        'image_id': i,\n",
    "        'question_id': i,\n",
    "        'feature_path': 'test/' + f'{image_name}.npy',\n",
    "        'question_str': ann['question'],\n",
    "        'question_tokens': tokenize(ann['question']),\n",
    "        'ocr_tokens': ocr_tokens[:7],\n",
    "    }\n",
    "    \n",
    "    res.append(item)\n",
    "    # print(item)\n",
    "    # break\n",
    "    \n",
    "np.save(\"./datasets/vizwiz/pythia_annotations_paddleocr/imdb_vizwiz_test.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e988ef90-8e07-4a38-9d62-3e09b8907def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "4.511113306332115\n",
      "5.0\n",
      "10123\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_ocr = np.load(\"./datasets/vizwiz/pythia_annotations_paddleocr/imdb_vizwiz_train_val.npy\", allow_pickle=True)\n",
    "len_ocr = []\n",
    "for ann in train_ocr[1:]:\n",
    "    if len(ann['ocr_tokens']) != 0:\n",
    "        len_ocr.append(len(ann['ocr_tokens']))\n",
    "print(np.max(len_ocr))\n",
    "print(np.mean(len_ocr))\n",
    "print(np.median(len_ocr))\n",
    "print(len(len_ocr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387aaf18-07a6-4af3-a914-69bffbf37301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
